# configs/gpu_full.yaml
# 사용: A100 80GB x4, H100 등 (고사양)

_base_: base.yaml

model:
  max_seq_length: 4096
  quantization:
    enabled: false  # Full precision (bf16)

training:
  batch_size: 8
  gradient_accumulation: 4
