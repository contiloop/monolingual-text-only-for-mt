# @package _global_
# configs/experiment/96gb.yaml
# 96GB VRAM - 메모리 최대 활용 설정

training:
  batch_size: 5              # GPU당 배치 크기 (96GB 최적화)
  gradient_accumulation: 4   # effective batch size:
                             # - 단일 GPU: 5 × 4 = 20
                             # - 4-GPU DDP: 5 × 4 × 4 = 80
  learning_rate: 2e-4
  steps: 200000              # 충분한 학습 (기존 50,000 → 200,000)

# 학습 및 평가 모두에 사용되는 max_length
max_length: 1024             # 토크나이징 시 최대 길이 (99% 데이터 커버)

model:
  lora:
    r: 64                    # LoRA rank (기본값으로 복원)
    alpha: 128               # alpha도 복원
  quantization:
    load_in_4bit: false      # Full precision 사용
    load_in_8bit: false

data:
  chunking:
    max_chars: 3000          # 1024 토큰 ≈ 3000 chars (기본값)
