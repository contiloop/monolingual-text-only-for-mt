# ê¸ˆìœµ ë²ˆì—­ ëª¨ë¸ (MidM Financial Translation)

## ë¹ ë¥¸ ì‹œì‘

```bash
# 1. í´ë¡  & í™˜ê²½ ì„¤ì •
git clone https://github.com/contiloop/monolingual-text-only-for-mt.git
cd monolingual-text-only-for-mt
uv venv .venv && source .venv/bin/activate

# ê¸°ë³¸ ì„¤ì¹˜ (SDPA ì‚¬ìš©)
uv pip install -e .

# Flash Attention 2 ì„¤ì¹˜ (ì„ íƒì‚¬í•­, GPU ì„œë²„ ê¶Œì¥)
# - ìš”êµ¬ì‚¬í•­: CUDA 11.6+, GPU Compute Capability 8.0+ (Ampere ì´ìƒ: A100, RTX 30xx/40xx/50xx)
# - íš¨ê³¼: í•™ìŠµ ì†ë„ 20-30% í–¥ìƒ
# - ì£¼ì˜: CUDA ë²„ì „ì— ë§ì¶° ì†ŒìŠ¤ì—ì„œ ë¹Œë“œ (10-20ë¶„ ì†Œìš”)

# CUDA ë²„ì „ í™•ì¸
nvcc --version

# Flash Attention ì„¤ì¹˜ (í˜„ì¬ CUDA ë²„ì „ì— ë§ì¶° ìë™ ë¹Œë“œ)
pip install ninja packaging wheel
MAX_JOBS=4 pip install flash-attn --no-build-isolation

# 2. WandB ë¡œê·¸ì¸
wandb login

# 3. í•™ìŠµ ì‹¤í–‰ (Hydra + Experiment)
# 4x16GB GPU ê¸°ì¤€
torchrun --nproc_per_node=4 src/train.py experiment=4x16gb
```

### WandB ë¡œê·¸ì¸ ì•ˆ ë  ë•Œ (Jupyter/Lightning AI)

```bash
# ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ë¡œ ì‹¤í–‰
WANDB_API_KEY=your-api-key python src/train.py

# ë°©ë²• 2: Pythonì—ì„œ ì§ì ‘ ì„¤ì •
python -c "import os; os.environ['WANDB_API_KEY']='your-api-key'"

# ë°©ë²• 3: .netrc íŒŒì¼ ìƒì„±
echo "machine api.wandb.ai login user password YOUR_API_KEY" > ~/.netrc
```

> API Key í™•ì¸: https://wandb.ai/authorize

---

## ë°ì´í„° ì¤€ë¹„

### 1. í•™ìŠµ ë°ì´í„° (Monolingual) ì „ì†¡

**ë¡œì»¬ì—ì„œ ì••ì¶•:**
```bash
cd /path/to/local/data/processed
tar -czvf processed_data.tar.gz *.jsonl
```

**ë¡œì»¬ Macì—ì„œ ê³µê°œí‚¤ í™•ì¸**
```
cat ~/.ssh/id_rsa.pub
```

**ì„œë²„ë¡œ ì „ì†¡:**
```bash
# SSH (Vast.AI ë“±)
scp -P [í¬íŠ¸] processed_data.tar.gz root@[IP]:/workspace/monolingual-text-only-for-mt/data/processed/

# ë°±ê·¸ë¼ìš´ë“œ ì „ì†¡ (í„°ë¯¸ë„ ë‹«ì•„ë„ ê³„ì†ë¨)
nohup scp -P [í¬íŠ¸] data/processed/processed_data.tar.gz root@[IP]:/workspace/monolingual-text-only-for-mt/data/processed/ > scp_upload.log 2>&1 &
tail -f scp_upload.log  # ì§„í–‰ í™•ì¸

# ë˜ëŠ” Jupyter UIì—ì„œ Upload
```

**í•œ ì¤„ë¡œ ì‚­ì œ + ì „ì†¡ + ì••ì¶•í•´ì œ:**
```bash
ssh -p [í¬íŠ¸] root@[IP] "rm -rf /workspace/monolingual-text-only-for-mt/data/processed/*" && \
scp -P [í¬íŠ¸] data/processed/processed_data.tar.gz root@[IP]:/workspace/monolingual-text-only-for-mt/data/processed/ && \
ssh -p [í¬íŠ¸] root@[IP] "cd /workspace/monolingual-text-only-for-mt/data/processed && tar -xzvf processed_data.tar.gz && rm processed_data.tar.gz"
```

**ì„œë²„ì—ì„œ ì••ì¶• í•´ì œ (ìˆ˜ë™):**
```bash
cd /workspace/monolingual-text-only-for-mt/data/processed
tar -xzvf processed_data.tar.gz
```

### 2. í‰ê°€ìš© ë³‘ë ¬ ì½”í¼ìŠ¤ ë‹¤ìš´ë¡œë“œ

**ì„œë²„ì—ì„œ ì§ì ‘ ë‹¤ìš´ë¡œë“œ (ê¶Œì¥):**
```bash
pip install datasets
python -c "
from datasets import load_dataset
ds = load_dataset('lemon-mint/korean_english_parallel_wiki_augmented_v1')
ds.save_to_disk('data/eval/korean_english_parallel')
print('âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!')
"
```

**ë¡œì»¬ì—ì„œ ì „ì†¡í•˜ë ¤ë©´:**
```bash
# ë¡œì»¬
tar -czvf parallel_corpus.tar.gz korean_english_parallel_dataset/

# ì„œë²„
cd /workspace/monolingual-text-only-for-mt/data/eval
tar -xzvf parallel_corpus.tar.gz
mv korean_english_parallel_dataset korean_english_parallel
```

---

## í•™ìŠµ ì‹¤í–‰ (Experiment íŒ¨í„´)

ì´ í”„ë¡œì íŠ¸ëŠ” Hydraì˜ **Experiment** íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ í•˜ë“œì›¨ì–´ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.

### ì£¼ìš” í•™ìŠµ ëª…ë ¹ì–´

```bash
# ë‹¨ì¼ A100 80GB (Full precision bf16, 200K steps)
python src/train.py +experiment=96gb training.early_stopping.enabled=false

# 4Ã— RTX 4080/5080 16GB (4-bit QLoRA)
torchrun --nproc_per_node=4 src/train.py +experiment=4x16gb

# A100 40-80GB ë©€í‹° GPU (8-bit)
torchrun --nproc_per_node=4 src/train.py +experiment=a100

# ë””ë²„ê¹… ëª¨ë“œ (1 step ì‹¤í–‰, ì €ì¥ ì•ˆ í•¨)
python src/train.py +experiment=debug

# CLIì—ì„œ ê°’ override (ì‹¤í—˜ config ìœ„ì— ë®ì–´ì“°ê¸°)
python src/train.py +experiment=96gb training.batch_size=8 training.steps=100000
```

### Iterative Back-Translation Workflow

ì´ í”„ë¡œì íŠ¸ëŠ” **iterative BT (back-translation)** ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

1. **Phase 1 (0~5000 steps)**: L_autoë§Œìœ¼ë¡œ denoising í•™ìŠµ
2. **Step 5000**: í•™ìŠµ ìë™ ì¤‘ë‹¨ â†’ BT ë°ì´í„° ìƒì„± í•„ìš”
3. **Phase 2 (5000~10000)**: L_auto + L_back ë™ì‹œ í•™ìŠµ
4. **Step 10000**: ë‹¤ì‹œ ì¤‘ë‹¨ â†’ BT ì¬ìƒì„± (ë” ì¢‹ì€ í’ˆì§ˆ)
5. ë°˜ë³µ...

#### BT Generation Mode ì„¤ì •

```yaml
# configs/training/default.yaml
bt_generation_mode: 'pause'  # ê¸°ë³¸ê°’: í•™ìŠµ ì¤‘ë‹¨ í›„ ìˆ˜ë™ ìƒì„±
# 'online': í•™ìŠµ ì¤‘ ìë™ ìƒì„± (GPU ë©”ëª¨ë¦¬ ì¶©ë¶„í•  ë•Œë§Œ)
# 'manual': BT ìŠ¤í‚µí•˜ê³  ê³„ì† í•™ìŠµ
```

#### ì¼ë°˜ì ì¸ ì›Œí¬í”Œë¡œìš°

**1ë‹¨ê³„: ì´ˆê¸° í•™ìŠµ ì‹œì‘**
```bash
python src/train.py
# Step 5000ì— ìë™ ì¤‘ë‹¨ë˜ë©° BT generation ëª…ë ¹ì–´ ì¶œë ¥ë¨
```

**2ë‹¨ê³„: BT ë°ì´í„° ìƒì„±** (í•™ìŠµ ì¤‘ë‹¨ëœ ìƒíƒœì—ì„œ)

âš ï¸ **ì¤‘ìš”**: ì–‘ë°©í–¥(Koreanâ†”English) ëª¨ë‘ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤!

```bash
# Step 2-1: Korean â†’ English
python src/bt/transformers_generator.py \
    --base_model K-intelligence/Midm-2.0-Base-Instruct \
    --adapter ./outputs/ckpt_5000 \
    --input_file ./data/processed/ko_processed.jsonl \
    --output_file ./data/bt_cache/bt_5000_ko_to_en.jsonl \
    --direction ko_to_en \
    --max_samples 10000 \
    --batch_size 64

# Step 2-2: English â†’ Korean
python src/bt/transformers_generator.py \
    --base_model K-intelligence/Midm-2.0-Base-Instruct \
    --adapter ./outputs/ckpt_5000 \
    --input_file ./data/processed/en_processed.jsonl \
    --output_file ./data/bt_cache/bt_5000_en_to_ko.jsonl \
    --direction en_to_ko \
    --max_samples 10000 \
    --batch_size 64
```

ğŸ’¡ **íŒ**: GPU ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë©´ ë‘ ëª…ë ¹ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰ ê°€ëŠ¥ (tmux/screen ì‚¬ìš©)

**3ë‹¨ê³„: í•™ìŠµ ì¬ê°œ**
```bash
python src/train.py training.resume_from_checkpoint="./outputs/ckpt_5000"
# Step 10000ì— ë‹¤ì‹œ ì¤‘ë‹¨ â†’ BT ì¬ìƒì„± â†’ ë°˜ë³µ
```

### WandB ëª¨ë‹ˆí„°ë§

í•™ìŠµ ì¤‘ ë‹¤ìŒì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- **Loss ê·¸ë˜í”„**: Training/Validation loss ì¶”ì´
- **Denoising Samples**: Noisy â†’ Generated â†’ Original ë¹„êµ (Table)
- **BLEU Score**: ë²ˆì—­ í’ˆì§ˆ (ë³‘ë ¬ ì½”í¼ìŠ¤ ì‚¬ìš© ì‹œ)

WandB í”„ë¡œì íŠ¸: `https://wandb.ai/YOUR_USERNAME/midm-12b-financial-translation`

---

## Config êµ¬ì¡° (Hydra)

```
configs/
â”œâ”€â”€ config.yaml           # ë©”ì¸ (defaults ì •ì˜)
â”œâ”€â”€ model/
â”‚   â””â”€â”€ midm.yaml         # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ training/
â”‚   â””â”€â”€ default.yaml      # í•™ìŠµ ê¸°ë³¸ ì„¤ì •
â”œâ”€â”€ data/
â”‚   â””â”€â”€ default.yaml      # ë°ì´í„° ê²½ë¡œ
â””â”€â”€ experiment/           # í•˜ë“œì›¨ì–´/ì‹¤í—˜ í”„ë¡œí•„ (ì„¤ì • ë®ì–´ì“°ê¸°)
    â”œâ”€â”€ 4x16gb.yaml       # 4-bit, Gradient Acc 16
    â”œâ”€â”€ a100.yaml         # 8-bit, Gradient Acc 4
    â””â”€â”€ debug.yaml        # ë””ë²„ê¹…ìš©
```

**ì¥ì :**
- GPUë³„ configì—ëŠ” overrideë§Œ ì‘ì„± (ì¤‘ë³µ ì œê±°)
- CLIì—ì„œ `training.batch_size=2` í˜•íƒœë¡œ ì¦‰ì‹œ ë³€ê²½
- ì‹¤í—˜ ê²°ê³¼ ìë™ ì €ì¥: `outputs/í”„ë¡œì íŠ¸ëª…/ë‚ ì§œ/ì‹œê°„/`

---

## Denoising í•™ìŠµ ì „ëµ

ì´ í”„ë¡œì íŠ¸ëŠ” **Monolingual Denoising**ì„ í†µí•´ ë²ˆì—­ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. ë…¸ì´ì¦ˆê°€ ì„ì¸ í…ìŠ¤íŠ¸ë¥¼ ì›ë³¸ìœ¼ë¡œ ë³µì›í•˜ëŠ” ê³¼ì •ì—ì„œ ì–¸ì–´ì˜ êµ¬ì¡°ì™€ í‘œí˜„ë ¥ì„ í•™ìŠµí•©ë‹ˆë‹¤.

### ëª©í‘œ
- **L_auto (Denoising)**: ë…¸ì´ì¦ˆ â†’ ì›ë³¸ ë³µì›
- **L_back (Back-Translation)**: ë²ˆì—­ í’ˆì§ˆ í–¥ìƒ (Phase 2)

### í•µì‹¬ ì „ëµ

#### 1. Infilling ìœ„ì£¼ ë…¸ì´ì¦ˆ (60%)
```yaml
# configs/data/default.yaml
noise:
  infilling_prob: 0.60  # [MASK] í† í°ìœ¼ë¡œ ëŒ€ì²´ - ë³µì‚¬ ë¶ˆê°€ëŠ¥
```
- **Why**: ë‹¨ìˆœ typoëŠ” ë³µì‚¬í•´ë„ 85% ì •í™• â†’ trivial copy í•™ìŠµ
- **Solution**: `[MASK]`ë¡œ ë§ˆìŠ¤í‚¹í•˜ë©´ ë¬¸ë§¥ ì¶”ë¡  ê°•ì œ

#### 2. Dynamic Noise Scheduling (0-40%)
```yaml
noise:
  dynamic_noise: true
  dynamic_noise_min: 0.0
  dynamic_noise_max: 0.40
```
- **Why**: ê³ ì • ë¹„ìœ¨ â†’ ëª¨ë¸ì´ "N% ì±„ìš°ë©´ ë¨" íŒ¨í„´ ì•”ê¸°
- **Solution**: ë§¤ë²ˆ ëœë¤ ë¹„ìœ¨ â†’ ë¬¸ë§¥ ê¸°ë°˜ íŒë‹¨ í•™ìŠµ

#### 3. Clean Data Mix (15%)
```yaml
noise:
  clean_ratio: 0.15  # 15% í™•ë¥ ë¡œ ë…¸ì´ì¦ˆ ì—†ëŠ” ë°ì´í„°
```
- **Why**: ë…¸ì´ì¦ˆë§Œ ë³´ë©´ "ëª¨ë“  ë¬¸ì¥ì€ ê³ ì¥ë‚¨" í¸í–¥
- **Solution**: ë©€ì©¡í•œ ë¬¸ì¥ë„ ì„ì–´ì„œ Identity Mapping í•™ìŠµ

#### 4. Diff-Weighted Loss (10x)
```yaml
training_loss:
  diff_weight: 10.0  # ë…¸ì´ì¦ˆ ë³µì› ìœ„ì¹˜ì— 10ë°° ê°€ì¤‘ì¹˜
```
- **Why**: ë³µì‚¬ ì„±ê³µ(85%) vs ë³µì› ì‹¤íŒ¨(15%) ë™ë“± ì·¨ê¸‰
- **Solution**: í‹€ë¦° ìœ„ì¹˜ì— 10ë°° í˜ë„í‹° â†’ ë³µì›ì— ì§‘ì¤‘

#### 5. Instruction Prompt
```
Fix the errors in the following text: {noisy}

Corrected version: {clean}
```
- **Why**: `[DENOISE] ... [OUTPUT]` í† í°ì€ task ì˜ë¯¸ ë¶ˆë¶„ëª…
- **Solution**: ìì—°ì–´ ì§€ì‹œë¬¸ìœ¼ë¡œ task ëª…í™•í™”

### Config ì „ì²´ ì˜ˆì‹œ
```yaml
# configs/data/default.yaml
noise:
  total_ratio: 0.30
  clean_ratio: 0.15
  dynamic_noise: true
  dynamic_noise_min: 0.0
  dynamic_noise_max: 0.40
  infilling_prob: 0.60

training_loss:
  diff_weight: 10.0
```

### í…ŒìŠ¤íŠ¸ ë°©ë²•
```bash
# Noise ì ìš© í™•ì¸
python -c "
from src.data.noise import NoiseApplier, NoiseConfig
applier = NoiseApplier(NoiseConfig())
for i in range(5):
    text = 'This is a test sentence for denoising.'
    noisy, noise_type = applier.apply(text, 'en', '')
    print(f'[{noise_type}] {noisy}')
"
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°
```
.
â”œâ”€â”€ configs/              # Hydra config (ê³„ì¸µì )
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/        # í•™ìŠµ ë°ì´í„° (ko/en_processed.jsonl)
â”‚   â””â”€â”€ eval/             # í‰ê°€ìš© ë³‘ë ¬ ì½”í¼ìŠ¤
â”œâ”€â”€ src/                  # í•™ìŠµ ì½”ë“œ
â””â”€â”€ outputs/              # ì²´í¬í¬ì¸íŠ¸ (ìë™ ìƒì„±)
```
