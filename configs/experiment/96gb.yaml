# @package _global_
# configs/experiment/96gb.yaml
# 96GB VRAM - 메모리 안전 설정

training:
  batch_size: 1              # GPU당 배치 크기 (메모리 안전)
  gradient_accumulation: 16  # effective batch size:
                             # - 단일 GPU: 1 × 16 = 16
                             # - 4-GPU DDP: 1 × 4 × 16 = 64
  learning_rate: 2e-4

# DataLoader의 tokenizer max_length (중요!)
max_length: 1024             # 토크나이징 시 최대 길이 (안전한 길이)

model:
  max_seq_length: 1024       # 모델 최대 시퀀스 길이
  lora:
    r: 64                    # LoRA rank (기본값으로 복원)
    alpha: 128               # alpha도 복원
  quantization:
    load_in_4bit: false      # Full precision 사용
    load_in_8bit: false

data:
  chunking:
    max_chars: 3000          # 1024 토큰 ≈ 3000 chars (기본값)
